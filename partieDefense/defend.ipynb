{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from graphique import *\n",
    "import numpy as np\n",
    "import datetime\n",
    "from morse3 import Morse as m\n",
    "import string, random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_file_url = \"https://drive.usercontent.google.com/download?id=1KE4dJ_ArA7jhIUYmzITIYO7Yh60rQ0-K&export=download&authuser=2&confirm=t&uuid=5b074238-7709-408b-ac93-86cf839cdb07&at=APZUnTXJHY4NiV5TeGbmEtE-F6Ip:1699105244012\"\n",
    "\n",
    "# Charger le fichier de vérité dans un dataframe sans le télécharger\n",
    "df = pd.read_csv(\"../truth_ground.csv\", delimiter= '\\t', header=None)    \n",
    "df.columns = [\"id\",\"date\", \"long\", \"lat\"]\n",
    "print(df.head(2))\n",
    "# Ajout de colonnes pour aider au traitement\n",
    "df['isPoi'] = [False]*df.shape[0]\n",
    "df['night'] = [False]*df.shape[0]\n",
    "df['work'] = [False]*df.shape[0]\n",
    "df['weekend'] = [False]*df.shape[0]\n",
    "df['semaine'] = pd.to_datetime(df['date'], format=\"%Y-%m-%d %H:%M:%S\").dt.isocalendar().week\n",
    "\n",
    "columns_types = {'id' : np.int16, 'date': str, 'long': np.float32, 'lat': np.float32, \n",
    "                 'isPoi' : bool, 'night': bool, 'work': bool, 'weekend': bool, 'semaine': np.int16}\n",
    "df = df.astype(columns_types)\n",
    "\n",
    "# Bucketisation en tuiles représentant des quartiers (arrondi 0.01)\n",
    "df['long'] = df['long'].apply(lambda x : round(x, 3))\n",
    "df['lat'] = df['lat'].apply(lambda x : round(x, 3))\n",
    "print(df.shape)\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids_to_treat = range(1, 113)\n",
    "#df_to_treat = df[(df['id'].isin(ids_to_treat))]\n",
    "df_to_treat = df\n",
    "print(df_to_treat[df_to_treat['id']==1])\n",
    "#df_to_treat[['id', 'date', 'long', 'lat']].to_csv(\"file2.csv\", sep=\"\\t\", index=False, header=False)\n",
    "#print(df_to_treat.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_treat.loc[4570486]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Découper en tuiles plus petites que les tuiles finales pour pouvoir supprimer des lignes de POI plus tard\n",
    "# Déterminer les poi pour les garder intègres au maximum\n",
    "# Décaler les heures de 6h tout en gardant la même durée totale passée dans ces poi -- Distribution normale...\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "WORK_START = datetime.time(9, 0)\n",
    "WORK_END = datetime.time(16, 0)\n",
    "WEEKEND_START = datetime.time(10, 0)\n",
    "WEEKEND_END = datetime.time(18, 0)\n",
    "NIGHT_START = datetime.time(22, 0)\n",
    "NIGHT_END = datetime.time(6, 0)\n",
    "\n",
    "def computePOIs(df_: pd.DataFrame, file_name):\n",
    "    def timedelta_def(): return datetime.timedelta()\n",
    "    def defaultdicttimedalta(): return defaultdict(timedelta_def)\n",
    "    def defaultdictseption(): return defaultdict(defaultdicttimedalta)\n",
    "    def returnnone(): return None\n",
    "    maxdict = lambda dict: max(dict, key=lambda key: dict[key])\n",
    "    def diff_time(key, time1, last_date_tab):\n",
    "        if last_date_tab[key] is None:\n",
    "            last_date_tab[key] = time1\n",
    "            return datetime.timedelta()\n",
    "        else:\n",
    "            difference = time1 - last_date_tab[key]\n",
    "            last_date_tab[key] = time1\n",
    "            return difference\n",
    "    def getMaxElement(theDict):\n",
    "        result = defaultdict(timedelta_def)\n",
    "        for _ in range(3):\n",
    "            if len(theDict)==0:\n",
    "                break\n",
    "            key = maxdict(theDict)\n",
    "            result[key] = theDict[key]\n",
    "            del theDict[key]\n",
    "        return result\n",
    "    def track_deplacements(row, deplacements_par_horaire, last_date_original_tab):\n",
    "        key = row[0]\n",
    "        gps = (row[2], row[3])\n",
    "        date_time = datetime.datetime.fromisoformat(row[1][:19])\n",
    "\n",
    "        if date_time.weekday() < 5:\n",
    "            if NIGHT_START < date_time.time() or date_time.time() < NIGHT_END:\n",
    "                deplacements_par_horaire[key]['night'][gps] += diff_time(key, date_time, last_date_original_tab)\n",
    "            elif WORK_START < date_time.time() < WORK_END:\n",
    "                deplacements_par_horaire[key]['work'][gps] += diff_time(key, date_time, last_date_original_tab)\n",
    "        else:\n",
    "            if WEEKEND_START < date_time.time() < WEEKEND_END:\n",
    "                deplacements_par_horaire[key]['weekend'][gps] += diff_time(key, date_time, last_date_original_tab) \n",
    "    \n",
    "    #--------------------------------------------------------#\n",
    "    # Détermination de l'horaire de chaque entrée du df\n",
    "    #--------------------------------------------------------#\n",
    "    tmp = pd.to_datetime(df_['date'])\n",
    "    conditions = [\n",
    "        (tmp.dt.weekday < 5) & ((tmp.dt.time > NIGHT_START) | (tmp.dt.time < NIGHT_END)),\n",
    "        (tmp.dt.weekday < 5) & ((WORK_START < tmp.dt.time) & (tmp.dt.time< WORK_END)),\n",
    "        (tmp.dt.weekday >= 5) & ((WEEKEND_START < tmp.dt.time) & (tmp.dt.time< WEEKEND_END))\n",
    "    ]\n",
    "    horaires = ['night', 'work', 'weekend']\n",
    "    for condition, horaire in zip(conditions, horaires):\n",
    "        df_.loc[condition, horaire] = True\n",
    "    \n",
    "    #--------------------------------------------------------#\n",
    "    # Calcul des durées passées dans à position gps pour chaque id\n",
    "    #--------------------------------------------------------#\n",
    "    deplacements_par_horaire = defaultdict(defaultdictseption)\n",
    "    last_date_original_tab = defaultdict(returnnone)\n",
    "    \n",
    "    fd_original = open(file_name, newline='')\n",
    "    original_reader = csv.reader(fd_original, delimiter=\"\\t\")\n",
    "    \n",
    "    for row in original_reader:\n",
    "        track_deplacements(row, deplacements_par_horaire, last_date_original_tab)\n",
    "    \n",
    "    #--------------------------------------------------------#\n",
    "    # Calcul des positions POI de niveau 1\n",
    "    #--------------------------------------------------------#\n",
    "    final_tab = defaultdict(defaultdictseption)\n",
    "    for id in deplacements_par_horaire:\n",
    "        for type in deplacements_par_horaire[id]:\n",
    "            final_tab[id][type] = getMaxElement(deplacements_par_horaire[id][type])\n",
    "\n",
    "    poi = []\n",
    "    for id in final_tab:\n",
    "        vartmp = {'id': id, 'night': None, 'work': None, 'weekend': None, 'duree_night': None, 'duree_work': None, 'duree_weekend': None}\n",
    "        for champ in final_tab[id]:\n",
    "            vartmp[champ] = max(final_tab[id][champ], key=lambda x: final_tab[id][champ][x])\n",
    "            delta_duree = final_tab[id][champ][vartmp[champ]]\n",
    "            vartmp['duree_'+str(champ)] =  (delta_duree.days * 24 * 3600) + delta_duree.seconds\n",
    "            isPoiCondition = (df_[champ]) & \\\n",
    "                (df_['id']==np.int16(id)) & \\\n",
    "                (df_['long']==float(vartmp[champ][0])) & \\\n",
    "                (df_['lat']==float(vartmp[champ][1]))\n",
    "                \n",
    "            df_.loc[isPoiCondition, 'isPoi'] = True  \n",
    "        poi.append(vartmp)\n",
    "    return poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_to_treat = df\n",
    "allPoi = computePOIs(df_to_treat, \"file1.csv\")\n",
    "print(allPoi)\n",
    "#print(df_to_treat.head(5))\n",
    "print(df_to_treat[df_to_treat['isPoi']==True].shape[0], df_to_treat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_to_treat[df_to_treat['night']==True].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permuteData(df: pd.DataFrame, to_poi_entries:bool | None =False):\n",
    "    groups_indexes, groups_idx = zip(*[(group_indexes, idx) for idx, group_indexes in df.groupby(['id', 'semaine']).groups.items()])\n",
    "    groups_indexes = list(groups_indexes)\n",
    "    groups_idx_listified = list(groups_idx)\n",
    "    groups_idx = set(groups_idx)\n",
    "    groups_traites_idx = set()\n",
    "\n",
    "    def pickAnotherGroupInTmp(current_group: Tuple):\n",
    "        remaining_groups = list(groups_idx - groups_traites_idx)\n",
    "        remaining_groups.remove(current_group)\n",
    "        if len(remaining_groups)!=0:\n",
    "            priority_groups = list(set([a for a in remaining_groups if a[0] != current_group[0]]))\n",
    "            if len(priority_groups) > 0: other_group = random.choice(priority_groups)\n",
    "            else: other_group = random.choice(remaining_groups)\n",
    "            group_position = groups_idx_listified.index(other_group)\n",
    "            return groups_indexes[group_position]\n",
    "    \n",
    "    for idx, group in df.groupby(['id', 'semaine']).groups.items():        \n",
    "        if to_poi_entries is not None:\n",
    "            poi_condition = (df.loc[group, 'isPoi'] == to_poi_entries)\n",
    "            group = group[poi_condition]\n",
    "        df_group = df.loc[group]\n",
    "        if idx not in groups_traites_idx :\n",
    "            other_group_indexes = pickAnotherGroupInTmp(idx)\n",
    "            if other_group_indexes is not None :\n",
    "                if to_poi_entries is not None:\n",
    "                    poi_condition = (df.loc[other_group_indexes, 'isPoi'] == to_poi_entries)\n",
    "                    other_group_indexes = other_group_indexes[poi_condition]\n",
    "                other_group = df.loc[other_group_indexes]\n",
    "                if not other_group.empty :\n",
    "                    a = df_group[['long', 'lat']].copy()\n",
    "                    b = other_group[['long', 'lat']].copy()                \n",
    "                    if a.shape[0] < b.shape[0]:\n",
    "                        df.loc[group, ['long', 'lat']] = b.iloc[:a.shape[0], :].values\n",
    "                        df.loc[other_group_indexes, ['long', 'lat']].iloc[:a.shape[0], :] = a.values                    \n",
    "                    else:\n",
    "                        df.loc[group, ['long', 'lat']].iloc[ : b.shape[0], :] = b.values\n",
    "                        df.loc[other_group_indexes, ['long', 'lat']] = a.iloc[:b.shape[0], :].values\n",
    "\n",
    "                    groups_traites_idx.add(tuple(idx))\n",
    "                    groups_traites_idx.add(tuple((other_group['id'].iloc[0], other_group['semaine'].iloc[0])))        \n",
    "    return df\n",
    "df_to_treat = permuteData(df_to_treat, to_poi_entries=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[(df['long'] != df_to_treat['long']) | (df['lat']!=df_to_treat['lat'])].shape, df_to_treat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftHour(entry) ->str:\n",
    "    originalDate = datetime.datetime.fromisoformat(entry)\n",
    "    shiftValue = -18 if originalDate.time()>=datetime.time(18,00) else 6\n",
    "    shiftedDate = originalDate + datetime.timedelta(hours=shiftValue)\n",
    "    entry = shiftedDate.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteData(df: pd.DataFrame, to_poi_entries:bool|None =False, proportion=1/3):\n",
    "    def suppressionAleatoire(group):\n",
    "        tmp = group[group['isPoi']==to_poi_entries] if to_poi_entries is not None else group\n",
    "        tailleSup = int(len(tmp)*proportion)\n",
    "        indices_to_remove = np.random.choice(tmp.index, size=tailleSup, replace=False)\n",
    "        group.loc[indices_to_remove, 'id'] = 'DEL'\n",
    "        return group\n",
    "    df['id']= df.groupby(['id', 'semaine'], group_keys=True, sort=False).apply(suppressionAleatoire)['id'].values\n",
    "    return\n",
    "\n",
    "deleteData(df_to_treat, to_poi_entries=False, proportion=0)\n",
    "print(df_to_treat.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterr = ((df_to_treat['id'] != 'DEL') &(df_to_treat['id'] != df['id'])) | (df_to_treat['semaine'] != df['semaine'])\n",
    "print(df_to_treat[filterr].shape, df_to_treat[filterr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_to_treat[df_to_treat['id']=='DEL'].shape[0], df_to_treat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisifyGps(df_part: pd.DataFrame):\n",
    "    noise = np.random.choice([-0.02, 0.02], size=(len(df_part), 2))\n",
    "    df_part[['long', 'lat']] += noise\n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter = (~df_to_treat['isPoi']) & (df_to_treat['id'] != 'DEL')\n",
    "#filter = (~df_to_treat['isPoi'])\n",
    "#df_to_treat[filter] = noisifyGps(df_to_treat[filter])\n",
    "df_to_treat = noisifyGps(df_to_treat)\n",
    "print(df_to_treat.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARACTERS_POOL = string.ascii_letters + string.digits\n",
    "CORRESPONDANCES_FILE =  'correspondances3.json'\n",
    "\n",
    "def generatePseudoIds(df_ : pd.DataFrame):\n",
    "    def generator(group, nb_characters : int):\n",
    "        pseudo_id_str = ''.join(random.choice(CHARACTERS_POOL) for _ in range(nb_characters))\n",
    "        pseudo_id_final = m(pseudo_id_str).stringToMorse().replace(\" \", \"\")\n",
    "        group.loc[group!='DEL'] = pseudo_id_final\n",
    "        #print(group)\n",
    "        return group\n",
    "\n",
    "    def saveCorrespondances(group:pd.DataFrame, corresp_struc: Dict):\n",
    "        tmp = group.loc[group['id'] != 'DEL' ,['id', 'id_x']]\n",
    "        id_original = int(tmp['id'].iloc[0]) if not tmp.empty else 'DEL'\n",
    "        if id_original == 'DEL':\n",
    "            return group\n",
    "        pseudo_id_final = tmp['id_x'].iloc[0]\n",
    "\n",
    "        if id_original not in corresp_struc:\n",
    "            corresp_struc[id_original] = {}\n",
    "        semaine = f\"2015-{group['semaine'].iloc[0]}\"\n",
    "        if  semaine not in corresp_struc[id_original]:\n",
    "            corresp_struc[id_original][semaine] = []\n",
    "        corresp_struc[id_original][semaine].append(pseudo_id_final)\n",
    "        return group\n",
    "\n",
    "    data = {}\n",
    "    df_['id_x'] = df_['id']   \n",
    "    df_['id_x'] = df_.groupby(['id', 'semaine'])['id_x'].transform(lambda group: generator(group, nb_characters=5))\n",
    "    df_.groupby(['id', 'semaine'], group_keys=True).apply(lambda group : saveCorrespondances(group, corresp_struc=data))\n",
    "    \n",
    "    with open(CORRESPONDANCES_FILE, 'w') as f:\n",
    "        json.dump(data, f, indent=4, separators=(',', ':'))\n",
    "    return df_\n",
    "\n",
    "b = generatePseudoIds(df_to_treat.copy())\n",
    "print(b.head(5))\n",
    "b[['id_x', 'date', 'long', 'lat']].to_csv(\"anonym3.csv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import pointsOfInterest, hour, meet, date, distance, tuile\n",
    "def calculScore(originial_f, anonymise_f):\n",
    "    metrics = []\n",
    "    for metric in [pointsOfInterest, hour, meet, date, distance, tuile]:\n",
    "        metrics.append(metric.main(originial_f, anonymise_f))\n",
    "    return metrics\n",
    "calculatedMetrics = calculScore(\"file3.csv\", \"anonym3.csv\")\n",
    "print(calculatedMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "score = np.mean(calculatedMetrics)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def calculateReidentificationScore(json_correct, json_soumis):\n",
    "    score = 0\n",
    "    nb_pseudo = 0\n",
    "    with open(json_correct, 'r') as f:\n",
    "        data_correct = json.load(f)\n",
    "\n",
    "    with open(json_soumis, 'r') as f:\n",
    "        data_soumis = json.load(f)\n",
    "\n",
    "    for id, semaines_correctes in data_correct.items():\n",
    "            # Comparer les pseudo-identifiants pour chaque semaine\n",
    "            for semaine, pseudo_id_correct in semaines_correctes.items():\n",
    "                nb_pseudo += 1\n",
    "                if id in data_soumis:\n",
    "                    pseudo_id_soumis = data_soumis[id].get(semaine, None)\n",
    "                    # Vérifier les correspondances\n",
    "                    if pseudo_id_soumis and pseudo_id_correct[0] == pseudo_id_soumis[0]:\n",
    "                        score += 1\n",
    "    print(f\"Score={score}/{nb_pseudo}\")\n",
    "    return score/nb_pseudo\n",
    "calculateReidentificationScore('correspondances3.json', '../partieAttaque/autoAttaques/sub2.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
